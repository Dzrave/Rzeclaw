# Rzeclaw 长期记忆系统：底层逻辑与架构设计

本文档设计一套**长期记忆（LTM）**的底层逻辑与架构，主旨包括：

- **不丢失、不混乱、不幻觉**：记忆可持久、可追溯、可校验，回答有据可查。
- **良好追溯**：每条记忆可追溯到来源（何时、何会话、何轮、用户/模型/工具）。
- **任务智能识别**：能区分不同任务/意图，按任务关联与检索记忆。
- **稳定资料来源**：对话时可依赖的、可引用的稳定记忆源。
- **智能且安全的长上下文**：在长上下文下仍可控、可审计、不串线。

---

## 一、设计原则（约束与目标）

| 原则 | 含义 |
|------|------|
| **可追溯（Provenance）** | 每条记忆带「来源锚点」：时间、会话 id、轮次、角色（user/model/tool）、原始片段引用。 |
| **只增不篡改（Append-only / Immutable）** | 写入以追加为主；修正/否定采用「新条目 + 指向旧条目」的方式，不静默覆盖，避免历史被改导致混乱。 |
| **检索即引用（Retrieve-to-Cite）** | 对话时从记忆库检索到的内容，必须以「可引用块」形式注入上下文，模型被约束为「仅基于检索结果作答」，减少幻觉。 |
| **任务/意图感知** | 记忆按任务/意图打标或聚类，检索时考虑当前任务，避免无关记忆干扰。 |
| **分层与安全边界** | 短期（会话内）、中期（会话间）、长期（跨会话持久）分层；访问与写入有明确边界（如仅限当前用户/工作区）。 |

---

## 二、记忆分层模型

```
┌─────────────────────────────────────────────────────────────────┐
│  L0：会话内工作记忆（Working Memory）                              │
│  内容：当前会话的最近 N 轮原始消息 + 工具调用/结果                  │
│  生命周期：会话存活期间；可选会话结束前压入 L1                     │
│  用途：当前轮推理、短时上下文                                      │
└─────────────────────────────────────────────────────────────────┘
                                    │ 摘要 / 关键事实抽取
                                    ▼
┌─────────────────────────────────────────────────────────────────┐
│  L1：会话摘要与事实（Session Summary & Facts）                     │
│  内容：会话级摘要、从会话中抽取的「事实/决策/偏好」条目             │
│  生命周期：持久；每条带完整来源（session_id, turn_range）           │
│  用途：跨会话检索、任务关联、避免重复问                             │
└─────────────────────────────────────────────────────────────────┘
                                    │ 去重、合并、任务聚类
                                    ▼
┌─────────────────────────────────────────────────────────────────┐
│  L2：长期记忆库（Long-term Memory Store）                         │
│  内容：结构化事实、用户偏好、项目/任务级知识、工具使用经验          │
│  生命周期：持久；支持更新仅通过「新事实 + 否定/替代关系」           │
│  用途：对话时稳定资料来源、任务识别、个性化与安全策略              │
└─────────────────────────────────────────────────────────────────┘
```

- **L0** 不要求单独存储引擎，沿用现有「当前会话消息列表」即可，但需在会话结束或达到阈值时，**有策略地**向 L1 写入（见下）。
- **L1/L2** 需要持久化存储与索引，建议统一抽象为「记忆存储层」，底层可实现为 SQLite + 全文/向量索引，或文档库 + 元数据。

---

## 三、单条记忆的数据结构（可追溯、防篡改）

每一条进入 L1/L2 的「记忆单元」建议至少包含以下字段，以保证不混乱、可追溯：

| 字段 | 类型 | 说明 |
|------|------|------|
| `id` | 唯一 id（如 UUID） |  immutable，全生命周期不变。 |
| `content` | 文本 | 记忆主体内容（事实/摘要/偏好等）。 |
| `content_type` | 枚举 | 如 `fact` / `summary` / `preference` / `task_outcome` / `tool_experience`。 |
| `provenance` | 结构体 | 见下表。 |
| `task_hint` | 可选字符串或向量 | 任务/意图标签或 embedding，用于任务感知检索。 |
| `validity` | 可选 | `active` / `superseded` / `contradicted`；若被后续否定，则新条目引用旧 id 并标记旧条为 `superseded` 或 `contradicted`。 |
| `created_at` | 时间戳 | 写入时间。 |
| `supersedes_id` | 可选 id | 若为修正/否定，指向被替代的旧记忆 id。 |

**provenance 结构体**（核心用于追溯）：

| 字段 | 说明 |
|------|------|
| `source_type` | `user` / `model` / `tool` / `system`。 |
| `session_id` | 来源会话。 |
| `turn_index` | 可选，来源轮次。 |
| `message_id` | 可选，来源消息或工具调用 id。 |
| `quote_start` / `quote_end` | 可选，在原文中的片段位置或原文摘要，便于「引用原文」校验。 |

这样，任何在对话中引用的记忆都可以回溯到「某次会话某轮用户/模型/工具说了什么」，避免幻觉与混乱。

---

## 四、写入流程：从会话到长期记忆（不丢、不篡改）

1. **触发时机**  
   - 会话结束（正常结束或超时）；或  
   - 会话内轮次达到阈值（如每 N 轮）；或  
   - 用户显式请求「记住这个」。

2. **从 L0 到 L1（会话级）**  
   - 用模型或规则从 L0 生成：  
     - 一段**会话摘要**（做了什么、主要结论）；  
     - 若干条**事实/决策/偏好**（结构化或半结构化）。  
   - 每条事实写入 L1 时即带完整 `provenance`（session_id, turn_range, source_type），并生成唯一 `id`。  
   - 不删除、不覆盖 L0 原始内容；仅追加写入 L1。

3. **从 L1 到 L2（可选，批处理或后台）**  
   - 对 L1 新条目做：去重（与已有 L2 事实相似度）、冲突检测（若与已有事实矛盾，写新事实并标记旧事实 `contradicted`，新事实 `supersedes_id` 指向旧 id）。  
   - 按 `content_type` 与 `task_hint` 归入 L2 的相应「桶」（如用户偏好、项目知识、工具经验）。  
   - 仍为追加式写入，不做静默覆盖。

4. **修正与否定**  
   - 用户说「之前说的 X 不对，应该是 Y」时：写新记忆条目标注 Y，并设 `supersedes_id` 指向表达 X 的旧记忆；旧记忆标记为 `superseded` 或 `contradicted`。  
   - 检索时可按策略过滤掉 `contradicted`/`superseded`，或同时返回并标注「已被替代」，由上层决定展示方式。

---

## 五、任务/意图的智能识别与记忆关联

目标：对不同任务有较智能的识别，记忆按任务关联，检索时「任务感知」。

- **任务表示**  
  - **显式**：用户说「我要做 A」「接下来处理 B」时，用模型抽取当前任务标签（短句或关键词），并在此后的若干轮内绑定到新产生的 L1 条目。  
  - **隐式**：对每条 L1/L2 条目，用轻量模型或关键词为其打上 `task_hint`（或 embedding），便于按任务聚类。

- **写入时**  
  - 每条写入 L1 的条目都带 `task_hint`（来自当前轮或近期轮的显式/隐式任务标签）。  
  - L2 聚合时保留或合并 `task_hint`，形成「任务 → 相关记忆」的索引。

- **检索时**  
  - 当前轮先做**当前意图/任务识别**（同一套任务标签或 embedding）。  
  - 检索条件 = （语义/关键词匹配 + **任务相关度** + 时间衰减等）。  
  - 这样「写文档」和「修 bug」不会混用对方的记忆，减少混乱与幻觉。

---

## 六、对话时作为「稳定资料来源」的检索与引用

目标：智能对话时调用的记忆是稳定、可引用的，且不幻觉。

- **检索流程**  
  1. 用当前用户输入（+ 可选当前任务标签）查 L1/L2，得到 Top-K 条记忆，每条带 `id`、`content`、`provenance`。  
  2. 将检索结果格式化为**带引用的上下文块**，例如：  
     `[Memory#id_xxx] (来自 session_abc 第 3 轮) content...`  
  3. 在 system 或 user 中注入：「以下为来自长期记忆的可靠内容，请仅基于此作答；若引用某条，请标明其 Memory#id 或来源。」

- **约束与安全**  
  - 模型侧指令：**仅基于检索到的记忆块作答，不得编造未在检索结果中出现的事实**；若无法从记忆中回答，明确说「当前记忆中没有相关信息」。  
  - 这样，对话中调用的「资料来源」稳定且可追溯，幻觉空间被压缩到「仅对检索结果的错误解读」，而解读错误仍可通过 Memory#id 回溯到原文校验。

- **分层检索策略**  
  - 先查 L2（长期事实/偏好/经验），再按需查 L1（近期会话事实）；或按时间/任务做混合排序。  
  - 返回结果带 `provenance`，便于在 UI 或日志中展示「根据哪次会话哪轮」。

---

## 七、长上下文记忆的智能与安全

- **不把所有历史都塞进上下文**  
  - 当前轮上下文 = **检索到的 L1/L2 记忆块（带引用）** + **当前会话 L0 的最近 N 轮**（或 L0 的摘要 + 最近 1～2 轮）。  
  - 长对话时，用「按轮摘要 + 固定窗口」管理 L0（与《优化与自我进化设计》一致），避免无限拉长。

- **安全边界**  
  - **隔离维度**：按 `user_id` / `workspace_id` 隔离记忆，避免跨用户/跨项目串线。  
  - **只读与写入分离**：对话时对 L1/L2 仅读；写入仅通过「会话结束/批处理/用户确认」的固定路径，且写入内容可审计（谁、何时、从哪条会话写入）。  
  - **敏感信息**：可选对写入 L1/L2 的内容做脱敏或禁止写入（如不把密钥、完整路径写入长期记忆），在写入前做简单规则或模型过滤。

- **容量与淘汰（可选）**  
  - L1 可按时间或条数做「冷归档」：超过一定时间未再被检索的条目移入冷存储，仍可追溯但不在热检索路径。  
  - L2 一般长期保留；若需淘汰，仅对「已被 superseded 且超过一定时间」的条目做归档或删除，且保留审计日志。

---

## 八、整体架构示意（与现有 Rzeclaw 的衔接）

```
                    ┌──────────────────┐
                    │   User / Client   │
                    └────────┬─────────┘
                             │
                    ┌────────▼─────────┐
                    │  Agent / Gateway │  ← 现有 Rzeclaw
                    │  (L0 工作记忆)   │
                    └────────┬─────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
         ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│ 记忆写入管道     │ │ 记忆检索服务     │ │ 任务识别         │
│ (会话结束/阈值)  │ │ (L1/L2 查询)    │ │ (当前意图标签)   │
└────────┬────────┘ └────────┬────────┘ └────────┬────────┘
         │                   │                   │
         └───────────────────┼───────────────────┘
                             │
                    ┌────────▼─────────┐
                    │  记忆存储层      │
                    │  - L1 索引       │
                    │  - L2 索引       │
                    │  - provenance    │
                    │  - task_hint     │
                    └────────┬─────────┘
                             │
                    ┌────────▼─────────┐
                    │  持久化存储      │
                    │  (SQLite/文档等) │
                    └─────────────────┘
```

- **Agent/Gateway** 在每轮前调用「记忆检索服务」+「任务识别」，将检索结果（带引用）注入上下文；在会话结束或达到阈值时调用「记忆写入管道」，将 L0 产出写入 L1（并可选推进到 L2）。  
- **记忆存储层** 对外提供：写入（追加）、按条件检索（含任务相关度）、按 id 查 provenance；底层用同一套 schema 与索引，保证可追溯与不篡改。

---

## 九、与「不丢失、不混乱、不幻觉」的对应关系

| 目标 | 设计手段 |
|------|----------|
| **不丢失** | 持久化 L1/L2；写入管道在会话结束/阈值时必跑；只增不删（除明确归档策略）。 |
| **不混乱** | 每条记忆带 provenance 与 task_hint；修正用新条目 + supersedes_id；检索按任务与时间排序。 |
| **不幻觉** | 对话仅基于「检索到的记忆块」作答，并强制引用 Memory#id/来源；不在上下文中混入未标注的「可能记错了」的内容。 |
| **良好追溯** | 任意展示的记忆都可回溯到 session_id、turn、source_type 及可选原文片段。 |
| **任务智能识别** | 写入与检索都带 task_hint/意图；检索时任务相关度参与排序。 |
| **稳定资料来源** | 检索结果以「带 id、带 provenance 的块」形式注入，并约束模型仅据此回答。 |
| **智能安全长上下文** | L0 用摘要+窗口；长上下文 = 检索结果 + L0 最近轮；按 user/workspace 隔离；写入可审计。 |

---

## 十、实现阶段建议（仍不实现，仅规划）

- **Phase 1**：定义记忆单元 schema（id, content, content_type, provenance, task_hint, validity, created_at, supersedes_id）与存储层接口（append, query_by_condition, get_provenance）。  
- **Phase 2**：实现 L1 写入管道（会话结束/阈值时从 L0 生成摘要与事实并写入），与基础检索（关键词或简单向量）。  
- **Phase 3**：任务识别（当前意图标签）+ 任务感知检索；检索结果格式化为带引用的上下文块，并在 Agent 中约束「仅基于检索结果作答」。  
- **Phase 4**：L2 与去重/冲突检测；supersedes 与 validity 管理；按 user/workspace 隔离与安全策略。  
- **Phase 5**：长上下文策略（L0 摘要+窗口）、冷归档与审计日志。

以上为长期记忆的底层逻辑与架构设计，可在评审后按阶段落地实现。
